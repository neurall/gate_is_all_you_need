basic idea spawned in my head when I watched recent descovery by blue brain folks? that some real biological dendrites fire to axon only when two simultaneous inputs to them fired in the same time. i.e they kinda worked like logical and  gate. Plus what is more important there was corelation detection per two dendrite connection in one neuron and one axon/neuron has houndreds of them in 
In reality one neron can be pretty dense state machine ? That would also explai how bio can do so much complex logic with so few neurons/layers ? So I started this repo hoping to create simple nn  but with logic gates behind weights. Could this be all they need without the need of any sort of gradient descent and backprop ? and addapt just by selecting or pruning gates ? Also I wanna test this as spiking networks since I feel frequencies play important role in nn inputs. I.e recently nerf needed to reintroduce sinuses to input to be actually able to learn and converge. transformers needed to introduce sinuses as positional encoding also. so why not work with frequencies as first class cityzens in a first place. after all evolution is not dumb if from all possible just binary spiking networks survived then there must be energy efficiency reason for it. with frequencies you get all the weird and wonderful world of standing reflected absorbed negated waves.
and gradients ans wawes are basic building block in 3d biological topology for a reason. ie thats how any living 3d organ is shaped from lowest molecule = 3d gradients and waves. all that is not present if we use just dumb floats as control freaks

So for logic gates . it turns out you need just one NAND and can create all 7 possible known logical circuits from it just by witing bunch of nands in specific way.
!(What-are-basic-logic-gates-figure-3.webp)
